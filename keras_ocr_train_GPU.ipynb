{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPQEvP0y_d02"
   },
   "source": [
    "# Fine-tuning recognizer with keras-ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fCivLsTi8qA",
    "outputId": "0bd823d9-324a-439c-e100-da8a31fab953"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import math\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import imgaug\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.model_selection\n",
    "import os\n",
    "import string \n",
    "\n",
    "import keras_ocr\n",
    "\n",
    "# Function to read labels file\n",
    "def _read_born_digital_labels_file(labels_filepath, image_folder):\n",
    "    \"\"\"Read a labels file and return (filepath, label) tuples.\n",
    "\n",
    "    Args:\n",
    "        labels_filepath: Path to labels file\n",
    "        image_folder: Path to folder containing images\n",
    "    \"\"\"\n",
    "    if not os.path.exists(labels_filepath):\n",
    "        raise FileNotFoundError(f\"Labels file not found: {labels_filepath}\")\n",
    "    if not os.path.exists(image_folder):\n",
    "        raise FileNotFoundError(f\"Image folder not found: {image_folder}\")\n",
    "\n",
    "    with open(labels_filepath, encoding=\"utf-8-sig\") as f:\n",
    "        labels_raw = [l.strip().split(\",\") for l in f.readlines()]\n",
    "        labels = [\n",
    "            (\n",
    "                os.path.join(image_folder, segments[0]),\n",
    "                None,\n",
    "                \",\".join(segments[1:]).strip()[1:-1],\n",
    "            )\n",
    "            for segments in labels_raw\n",
    "        ]\n",
    "    return labels\n",
    "\n",
    "# Specify the correct paths using raw strings to handle backslashes properly\n",
    "train_labels_filepath = r\"E:\\Bangkit\\Capstone\\Lintasarta\\OCR\\train\\Lintasarta\\train\\gt.txt\"\n",
    "train_image_folder = r\"E:\\Bangkit\\Capstone\\Lintasarta\\OCR\\train\\Lintasarta\\train\\image_file\"\n",
    "test_labels_filepath = r\"E:\\Bangkit\\Capstone\\Lintasarta\\OCR\\train\\Lintasarta\\test\\gt.txt\"\n",
    "test_image_folder = r\"E:\\Bangkit\\Capstone\\Lintasarta\\OCR\\train\\Lintasarta\\test\\image_file\"\n",
    "\n",
    "# Read the labels\n",
    "try:\n",
    "    train_labels = _read_born_digital_labels_file(labels_filepath=train_labels_filepath, image_folder=train_image_folder)\n",
    "    test_labels = _read_born_digital_labels_file(labels_filepath=test_labels_filepath, image_folder=test_image_folder)\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    # Handle the error appropriately, e.g., by exiting or providing a fallback\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "# Ensure the labels were loaded before proceeding\n",
    "if train_labels:\n",
    "    train_labels = [(filepath, box, word.lower()) for filepath, box, word in train_labels]\n",
    "else:\n",
    "    print(\"Train labels could not be loaded.\")\n",
    "\n",
    "if test_labels:\n",
    "    test_labels = [(filepath, box, word.lower()) for filepath, box, word in test_labels]\n",
    "else:\n",
    "    print(\"Test labels could not be loaded.\")\n",
    "\n",
    "# Verify if the labels are loaded correctly\n",
    "print(f'Number of training labels: {len(train_labels)}')\n",
    "print(f'Number of test labels: {len(test_labels)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbZicDRHjKCe",
    "outputId": "af5edcb1-5f84-424b-9dc1-cedf50c4e80a"
   },
   "outputs": [],
   "source": [
    "recognizer = keras_ocr.recognition.Recognizer(alphabet=string.printable)\n",
    "recognizer.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoMz6FAkjr13"
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "augmenter = imgaug.augmenters.Sequential([\n",
    "    imgaug.augmenters.GammaContrast(gamma=(0.25, 3.0)),\n",
    "])\n",
    "\n",
    "# Use the provided training and test labels\n",
    "training_labels = train_labels\n",
    "validation_labels = test_labels\n",
    "\n",
    "\n",
    "# Create image generators and calculate steps per epoch\n",
    "(training_image_gen, training_steps), (validation_image_gen, validation_steps) = [\n",
    "    (\n",
    "        keras_ocr.datasets.get_recognizer_image_generator(\n",
    "            labels=labels,\n",
    "            height=recognizer.model.input_shape[1],\n",
    "            width=recognizer.model.input_shape[2],\n",
    "            alphabet=recognizer.alphabet,\n",
    "            augmenter=augmenter if labels is training_labels else None\n",
    "        ),\n",
    "        len(labels) // batch_size\n",
    "    ) for labels in [training_labels, validation_labels]\n",
    "]\n",
    "\n",
    "# Create batch generators for training and validation\n",
    "training_gen, validation_gen = [\n",
    "    recognizer.get_batch_generator(\n",
    "        image_generator=image_generator,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    for image_generator in [training_image_gen, validation_image_gen]\n",
    "]\n",
    "# Print the number of training and validation images\n",
    "print(f\"Number of training images: {len(training_labels)}\")\n",
    "print(f\"Number of validation images: {len(validation_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "z2eHTeZW-lFt",
    "outputId": "6fd44096-7f8b-47b2-a305-6a974e9c21c3"
   },
   "outputs": [],
   "source": [
    "image, text = next(training_image_gen)\n",
    "print('text:', text)\n",
    "_ = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "bwfxrcKFjtxi",
    "outputId": "2707896f-1551-43ca-a659-93e7808d944d"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10000, restore_best_weights=False,start_from_epoch=0),\n",
    "    tf.keras.callbacks.ModelCheckpoint('train_24/05/2024.h5', monitor='val_loss', save_best_only=True),\n",
    "    tf.keras.callbacks.CSVLogger('recognizer_borndigital1.csv')\n",
    "]\n",
    "recognizer.training_model.fit_generator(\n",
    "    generator=training_gen,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_steps=validation_steps,\n",
    "    validation_data=validation_gen,\n",
    "    callbacks=callbacks,\n",
    "    epochs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepath, _, actual = test_labels[19]\n",
    "predicted = recognizer.recognize(image_filepath)\n",
    "print(f'Predicted: {predicted}, Actual: {actual}')\n",
    "_ = plt.imshow(keras_ocr.tools.read(image_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN-R_FFrJMiz"
   },
   "outputs": [],
   "source": [
    "recognizer.prediction_model.load_weights(os.path.join('train_25/05/2024.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "total_samples = len(test_labels)\n",
    "correct_predictions = 0\n",
    "total_characters = 0\n",
    "correct_characters = 0\n",
    "\n",
    "model_name = type(recognizer).__name__\n",
    "print(f\"Model used: {model_name}\")\n",
    "\n",
    "for image_filepath, _, actual in test_labels:\n",
    "    predicted = recognizer.recognize(image_filepath)\n",
    "    print(f'Predicted: {predicted}, Actual: {actual}')\n",
    "    _ = plt.imshow(keras_ocr.tools.read(image_filepath))\n",
    "    \n",
    "    total_characters += len(actual)\n",
    "    \n",
    "    if predicted == actual:\n",
    "        correct_predictions += 1\n",
    "        correct_characters += len(actual)\n",
    "    else:\n",
    "        for i in range(len(actual)):\n",
    "            if i < len(predicted) and actual[i] == predicted[i]:\n",
    "                correct_characters += 1\n",
    "\n",
    "accuracy = (correct_predictions / total_samples) * 100\n",
    "character_accuracy = (correct_characters / total_characters) * 100\n",
    "\n",
    "print(f'Overall Accuracy: {accuracy}%')\n",
    "print(f'Character Accuracy: {character_accuracy}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Get a set of three example images\n",
    "images = keras_ocr.tools.read('E:/Bangkit/Capstone/Lintasarta/OCR/train/inference/Army_Reserves_Recruitment_Banner_MOD_45156284.jpg')\n",
    "\n",
    "# Each list of predictions in prediction_groups is a list of\n",
    "# (word, box) tuples.\n",
    "prediction_groups = pipeline.recognize(images)\n",
    "\n",
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
